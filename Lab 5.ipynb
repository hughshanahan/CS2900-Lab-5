{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning outcomes of this session are\n",
    "\n",
    "\n",
    "-   To use SVD (using NumPy libraries) to carry out PCA.\n",
    "\n",
    "-   To demonstrate that eigenvectors and eigenvalues can also be used to do PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal Component Analysis \n",
    "========================\n",
    "\n",
    "There are a set of libraries for doing PCA on data (using scikit) in Python but here we will just use Numpy. \n",
    "\n",
    "First we will need some additional libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the PCA we will use a data set about cars. This is a standard data set that you can find in the statistical package R. The full data set can be found on the moodle page in the file mtcars.csv. It has a variety of data for 32 cars. For this exercise we will use a version of the data set where \n",
    "\n",
    "<ol>\n",
    "  <p>all the label data has been removed,</p>\n",
    "\n",
    "  <p>the columns with integer data (you could include it if you wished..) has also been removed.</p>\n",
    "\n",
    "</ol>\n",
    "\n",
    "Leaving us with 32 cars and 6 variables.\n",
    "\n",
    "Note - the order of the data is still the same (i.e. the first row corresponds to the Mazda RX4). \n",
    "\n",
    "The file can be read in as follows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcars = genfromtxt('cars.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the size of the array that has been read in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M,N = np.shape(mtcars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As dicussed in the notes, given a matrix of data $\\mathbf{T}$ we need to compute\n",
    "\n",
    "$\n",
    "x_{i,j} \\;\\; \\equiv \\;\\;  t_{i,j} \\,\\, - \\,\\, \\mu_i \\;\\; , \n",
    "$\n",
    "\n",
    "and define\n",
    "\n",
    "$\n",
    "\\mathbf{X}^\\intercal \\;\\; \\equiv \\;\\; \n",
    "\\begin{pmatrix}\n",
    "\\vdots & \\dots & \\vdots \\\\\n",
    "\\underline{x}_1 & & \\underline{x}_N \\\\\n",
    "\\vdots & \\dots & \\vdots \n",
    "\\end{pmatrix}\n",
    "$\n",
    "\n",
    "This process is called \"centreing\" as data in each column now has a mean of zero.\n",
    "\n",
    "We define the function below to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centreData( data ):\n",
    "    \"Compute means of columns of data and subtract that off data\"\n",
    "    means = np.mean(data,axis=0)\n",
    "    return data - means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XT = centreData(mtcars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check if the data is centred by computing the mean of the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(XT,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariance of the original data can be computed as \n",
    "\n",
    "$\n",
    "\\mathbf{C} \\;\\; = \\;\\; \\frac{1}{M-1} \\,  \\mathbf{X} \\, \\mathbf{X}^\\intercal \\;\\; . \n",
    "$\n",
    "\n",
    "The relevant function for this is computed below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance( data ):\n",
    "    \"Compute covariance of a data matrix\"\n",
    "    XT = centreData(data)\n",
    "    M = np.shape(data)[0]\n",
    "    return (1.0/(M-1.)) * np.dot(np.transpose(XT),XT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = covariance(mtcars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute the covariance matrix from the data using the function $\\tt{numpy.cov}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = np.cov(mtcars,rowvar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that C and C1 are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having computed the covariance matrix we want to express the data we have (written as $\\mathbf{X}^\\intercal$ in terms of a new set of coordinates $\\mathbf{Y}^\\intercal$ as \n",
    "\n",
    "$\n",
    "\\mathbf{Y}^\\intercal \\;\\; = \\;\\; \\mathbf{X}^\\intercal \\, \\mathbf{R}^\\intercal  \\;\\;,\n",
    "$\n",
    "\n",
    "where the covariance matrix for $\\mathbf{Y}^\\intercal$ and $C_Y$ is diagonal.\n",
    "\n",
    "$\n",
    "\\mathbf{C}_Y \\;\\; = \\;\\; \\mathbf{R} \\, \\mathbf{C} \\, \\mathbf{R}^\\intercal \\;\\; .\n",
    "$\n",
    "\n",
    "From the notes we see that if we perform SVD on $\\mathbf{X}^\\intercal$, i.e.\n",
    "\n",
    "$\n",
    "\\mathbf{X}^\\intercal = \\mathbf{U} \\mathbf{D} \\mathbf{V}^\\intercal\n",
    "$ \n",
    "\n",
    "and that  \n",
    "\n",
    "$\n",
    "\\mathbf{C}_Y = \\mathbf{V}^\\intercal \\mathbf{C}_X \\mathbf{V} = \\frac{1}{M-1} \\mathbf{D}^2 \\;\\;\\; (1)\n",
    "$\n",
    "\n",
    "$\n",
    "\\mathbf{Y}^\\intercal = \\mathbf{X}^\\intercal \\mathbf{V} \\;\\;\\; (2)\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U,D,Vt = np.linalg.svd(XT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From equation (2) compute YT below (Hint - you will need to know how to compute the transpose of a matrix). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT = ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check if YT has the same dimensions of XT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(YT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the covariance matrix $\\mathbf{C}_Y$ using equation (1). Note the $\\mathbf{D}$ is not a standard matrix (if we use the dot command then we just compute the dot product of $\\mathbf{D}$).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CY = (1/(M-1.)) * D * D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you think that using the first two components is a reasonable approximation? Why? (or Why not?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the data using the new axes (i.e. in terms of $\\mathbf{Y}^\\intercal$). To do this we will need matplotlib. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the components against each other. These are simply the columns of YT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC1 = np.transpose(YT)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC2 = np.transpose(YT)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PC1, PC2, 'o', label='PC1 versue PC2', markersize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a notable outlier in this plot. See if you can find the relevant row of YT which will correspond to the row of XT and then determine what car it is. Any possible reason it is an outlier?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC3 = np.transpose(YT)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a further check perform a plot of PC1 against PC3. What is notable about the scale? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PC1, PC3, 'o', label='PC1 versue PC3', markersize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the notes we can achieve the same task bycomputing the eigenvalues/vectors of $\\mathbf{C}$ we find that if $\\mathbf{D}$ and \n",
    "$\\mathbf{E}$ are the eigenvalues and eigenvectors of $\\mathbf{C}$ then \n",
    "\n",
    "$\n",
    "\\mathbf{R} = \\mathbf{E}^\\intercal \\;\\; \n",
    "$\n",
    "and the eigenvalues represent the variances of $\\mathbf{Y}^\\intercal$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D,E = np.linalg.eig(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT1 = XT.dot(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we check if both approaches match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
